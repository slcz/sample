{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import widgets, interact\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user = 'chris'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var command = [\"currenturl = \", \"'\", window.location.href, \"'\" ].join('')\n",
    "kernel.execute(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "o = urlparse(currenturl)\n",
    "hostname = o.hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifarpath = os.path.join('cifar-10', \"*.bin\")\n",
    "size           = 32\n",
    "color_channels = 3\n",
    "image_size     = size * size * color_channels\n",
    "label_size     = 1\n",
    "raw_size       = image_size + label_size\n",
    "inputraw       = []\n",
    "labelsraw      = []\n",
    "for cifarbinname in glob.glob(cifarpath):\n",
    "    with open(cifarbinname, 'rb') as cifarfile:\n",
    "        raw = cifarfile.read()\n",
    "        n_images = len(raw) // raw_size\n",
    "        offset = 0\n",
    "        for i in range(n_images):\n",
    "            single = np.frombuffer(raw, dtype=np.uint8, count=image_size, offset=offset + label_size)\n",
    "            labelsraw.append(raw[offset])\n",
    "            inputraw.append(single)\n",
    "            offset += raw_size\n",
    "print(\"TOTAL {} images\".format(len(inputraw)))\n",
    "images_ = np.stack(inputraw, axis = 0).reshape([-1, color_channels, size, size])\n",
    "labels_ = np.array(labelsraw, dtype=np.int32)\n",
    "with open(os.path.join('cifar-10', 'batches.meta.txt'), 'r') as metafile:\n",
    "    lines = metafile.readlines();\n",
    "label_text = [x.strip() for x in lines]\n",
    "nlabels = len(label_text)\n",
    "nimages = images_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_reshaped = images_.transpose([0,2,3,1])\n",
    "sort_index = np.argsort(labels_)\n",
    "images_sorted = images_reshaped[sort_index]\n",
    "labels_sorted = labels_[sort_index]\n",
    "plt.figure(figsize=(12,12))\n",
    "images_per_category = nimages // nlabels\n",
    "\n",
    "samples = 5\n",
    "for i in range(nlabels):\n",
    "    for j in range(samples):\n",
    "        index = random.randint(0, images_per_category - 1)\n",
    "        plt.subplot(samples, nlabels, j * nlabels + i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.xlabel(\"\")\n",
    "        plt.ylabel(\"\")\n",
    "        plt.imshow(images_sorted[i * images_per_category + index], interpolation='nearest')\n",
    "        if (j == 0):\n",
    "            plt.title(label_text[labels_sorted[i * images_per_category + index]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_images_and_labels(images, labels, numbers):\n",
    "    plt.figure(figsize=(12,12))\n",
    "    x = list(range(labels.size))\n",
    "    random.shuffle(x)\n",
    "    img_ = images[x]\n",
    "    lbl_ = labels[x]\n",
    "    for i in range(numbers):\n",
    "        plt.subplot(numbers, 1, i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.xlabel(\"\")\n",
    "        plt.ylabel(\"\")\n",
    "        plt.imshow(img_[i], interpolation='nearest')\n",
    "        plt.title(label_text[lbl_[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_images(images, labels):\n",
    "    x = list(range(images_reshaped.shape[0]))\n",
    "    random.shuffle(x)\n",
    "    return images_reshaped[x], labels[x]\n",
    "images, labels = shuffle_images(images_reshaped, labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2test_ratio = 6\n",
    "test_size  = images.shape[0] // train2test_ratio\n",
    "train_size = nimages - test_size\n",
    "train_images, test_images = np.split(images, [train_size])\n",
    "train_labels, test_labels = np.split(labels, [train_size])\n",
    "print(\"train_images shape = {} train_labels shape = {} test_images shape = {} test_labels shape = {}\".format(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "url = \"<iframe src=http://\" + hostname + \":8080/?user=\" + user + \" width=850 height=650></iframe>\"\n",
    "HTML(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelfile = os.path.join('model', user + '.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load model/chris.py\n",
    "def model(net):\n",
    "\n",
    "    net = tf.contrib.layers.conv2d(net, 64, [5,5], 1, activation_fn = tf.nn.relu, padding='SAME', scope='conv2')\n",
    "\n",
    "    net = tf.contrib.layers.max_pool2d(net, [3, 3], 2, padding='SAME', scope='pool3')\n",
    "\n",
    "    net = tf.nn.lrn(net, 4, bias = 1.00, alpha = 0.001/9.0, beta = 0.750, name = 'lrn4')\n",
    "\n",
    "    net = tf.contrib.layers.conv2d(net, 64, [5,5], 1, activation_fn = tf.nn.relu, padding='SAME', scope='conv5')\n",
    "\n",
    "    net = tf.nn.lrn(net, 4, bias = 1.00, alpha = 0.001/9.0, beta = 0.750, name = 'lrn6')\n",
    "\n",
    "    net = tf.contrib.layers.max_pool2d(net, [3, 3], 2, padding='SAME', scope='pool7')\n",
    "\n",
    "    net = tf.contrib.layers.flatten(net, scope='flatten8')\n",
    "    net = tf.contrib.layers.fully_connected(net, 384, activation_fn=tf.nn.relu, scope='fc9')\n",
    "\n",
    "    net = tf.contrib.layers.fully_connected(net, 192, activation_fn=tf.nn.relu, scope='fc10')\n",
    "\n",
    "    net = tf.contrib.layers.fully_connected(net, 10, activation_fn=None, scope='fc11')\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.input = tf.placeholder(dtype = tf.int32, shape = [None, size, size, color_channels], name = \"input\")\n",
    "        self.label = tf.placeholder(dtype = tf.int32, shape = [None], name = \"label\")\n",
    "        self.image = tf.placeholder(dtype = tf.int32, shape = [size, size, color_channels])\n",
    "        image = tf.cast(self.image, tf.float32)\n",
    "        self.standadize = tf.image.per_image_standardization(image)\n",
    "        self.randomize = tf.image.random_flip_left_right(image)\n",
    "        self.randomize = tf.image.random_brightness(self.randomize, max_delta = 63)\n",
    "        self.randomize = tf.image.random_contrast(self.randomize, lower=0.2, upper=1.8)\n",
    "        self.randomize = tf.image.per_image_standardization(self.randomize)\n",
    "        input_converted = tf.cast(self.input, tf.float32)\n",
    "        self.logits = model(input_converted)\n",
    "        self.probability = tf.nn.softmax(self.logits, name = \"probability\")\n",
    "        losses = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = self.label, logits = self.logits, name = 'losses')\n",
    "        self.loss = tf.reduce_mean(losses, name = 'loss')\n",
    "        optimizer = tf.train.RMSPropOptimizer(0.0003)\n",
    "        self.train = optimizer.minimize(self.loss, global_step = tf.contrib.framework.get_global_step())\n",
    "        tf.summary.scalar('loss', self.loss)\n",
    "        for s in tf.trainable_variables():\n",
    "            if 'weights' in s.name:\n",
    "                tf.summary.histogram(s.name, s)\n",
    "            if 'biases' in s.name:\n",
    "                tf.summary.histogram(s.name, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.contrib.framework.get_or_create_global_step()\n",
    "network = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver_path = os.path.join('saved_models', user)\n",
    "if not os.path.exists(saver_path):\n",
    "    os.makedirs(saver_path)\n",
    "init_op = tf.group(tf.global_variables_initializer(),\n",
    "                   tf.local_variables_initializer())\n",
    "session = tf.Session()\n",
    "session.run(init_op)\n",
    "summary_path = os.path.join('summary', user)\n",
    "if not os.path.exists(summary_path):\n",
    "    os.makedirs(summary_path)\n",
    "summary_writer = tf.summary.FileWriter(summary_path, session.graph)\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def restore(session, saver, path):\n",
    "    print(path)\n",
    "    checkpoint = tf.train.latest_checkpoint(path)\n",
    "    if checkpoint:\n",
    "        saver.restore(session, checkpoint)\n",
    "        steps = session.run(tf.contrib.framework.get_global_step())\n",
    "        print(\"restored model @ steps {}\".format(steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save(session, saver, path):\n",
    "    steps = session.run(tf.contrib.framework.get_global_step())\n",
    "    p = os.path.join(path, user)\n",
    "    saver.save(session, p, steps)\n",
    "    print(\"saved model @ steps {}\".format(steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standadize_batch(images):\n",
    "    size = images.shape[0]\n",
    "    acc = []\n",
    "    for i in range(size):\n",
    "        with tf.device('/cpu:0'):\n",
    "            processed, = session.run([network.standadize], feed_dict = {network.image : images[i]})\n",
    "            acc.append(processed)\n",
    "    post = np.stack(acc, axis = 0)\n",
    "    return post\n",
    "def randomize_batch(images):\n",
    "    size = images.shape[0]\n",
    "    acc = []\n",
    "    for i in range(size):\n",
    "        with tf.device('/cpu:0'):\n",
    "            processed, = session.run([network.randomize], feed_dict = {network.image : images[i]})\n",
    "            acc.append(processed)\n",
    "    post = np.stack(acc, axis = 0)\n",
    "    return post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restore(session, saver, saver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"EPOCH {}\".format(epoch + 1))\n",
    "    randomized_image = randomize_batch(train_images)\n",
    "    processed = 0\n",
    "    loss_acc = 0\n",
    "    total_trainings = 0\n",
    "    \n",
    "    while processed < train_size:\n",
    "        last = processed + batch_size\n",
    "        if last > train_size:\n",
    "            last = train_size\n",
    "        summary_step, _, loss_step, steps = session.run([merged, network.train, network.loss, tf.contrib.framework.get_global_step()],\n",
    "                                                       feed_dict = {network.input : randomized_image[processed:last],\n",
    "                                                                    network.label : train_labels[processed:last]})\n",
    "        loss_acc += loss_step\n",
    "        total_trainings += 1\n",
    "        if total_trainings % 100 == 0:\n",
    "            print(\"processed = {}\".format(processed))\n",
    "            summary_writer.add_summary(summary_step, steps)\n",
    "        processed = last\n",
    "    print(\"EPOCH {} DONE AVERAGE LOSS = {:.2f}\".format(epoch + 1, loss_acc / total_trainings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(session, saver, saver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_images_stand = standadize_batch(test_images)\n",
    "processed = 0\n",
    "correctly_predicted = 0\n",
    "while processed < test_size:\n",
    "    last= processed + batch_size\n",
    "    if (last > test_size):\n",
    "        last = test_size\n",
    "    probability, = session.run([network.probability], feed_dict = {network.input : test_images_stand[processed:last]})\n",
    "    labels = test_labels[processed:last]\n",
    "    predicted = np.argmax(probability, axis = 1)\n",
    "    correctly_predicted += np.sum(predicted == labels)\n",
    "    processed = last\n",
    "print(\"{} {} {:.2f}%\".format(correctly_predicted, processed, correctly_predicted / processed * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
